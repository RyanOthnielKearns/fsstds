{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: It's about time \n",
    "Thank you for checking out the code for: \n",
    "\n",
    "> Hogan, Bernie (2022, forthcoming) _From Social Science to Data Science_. Sage Publications. \n",
    "\n",
    "This notebook contains the code from the book, along with the headers and additional author notes that are not in the book as a way to help navigate the code. You can run this notebook in a browser by clicking the buttons below. \n",
    "    \n",
    "The version that is uploaded to GitHub should have all the results pasted, but the best way to follow along is to clear all outputs and then start afresh. To do this in Jupyter go the menu and select \"Kernel -> Restart Kernel and Clear all Outputs...\". To do this on Google Colab go to the menu and select \"Edit -> Clear all outputs\".\n",
    "    \n",
    "The most up-to-date version of this code can be found at https://www.github.com/berniehogan/fsstds \n",
    "\n",
    "Additional resources and teaching materials can be found on Sage's forthcoming website for this book. \n",
    "\n",
    "All code for the book and derivative code on the book's repository is released open source under the  MIT license. \n",
    "    \n",
    "\n",
    "[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/berniehogan/fsstds/main?filepath=chapters%2FCh.12.TimeSeries.ipynb)[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/berniehogan/fsstds/blob/main/chapters/Ch.12.TimeSeries.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Dates and the datetime module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-10 07:58:44.518171\n",
      "time.struct_time(tm_year=2022, tm_mon=5, tm_mday=10, tm_hour=7, tm_min=58, tm_sec=44, tm_wday=1, tm_yday=130, tm_isdst=-1)\n",
      "1652169524\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "print(now)\n",
    "print(now.timetuple())\n",
    "print(calendar.timegm(now.timetuple()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> Thu Apr 06 15:24:15 +0000 2017\n"
     ]
    }
   ],
   "source": [
    "# Taken from https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html\n",
    "\n",
    "tweet = {\n",
    " \"created_at\":\"Thu Apr 06 15:24:15 +0000 2017\",\n",
    " \"id\": 850006245121695744,\n",
    " \"id_str\": \"850006245121695744\",\n",
    " \"text\": \"1/ Today weâ€™re sharing our vision for the future of the Twitter API platform!nhttps://t.co/XweGngmxlP\",\n",
    " \"user\": {},\n",
    " \"entities\": {}\n",
    "}\n",
    "\n",
    "print(type(tweet['created_at']),tweet['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-04-06 15:24:15+0000', tz='UTC')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(tweet[\"created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original date was formatted as: Thu Apr 06 15:24:15 +0000 2017\n",
      "We can format it differenly, such as: 2017--06--Apr--Thu 15 and 24 and 15 +0000\n"
     ]
    }
   ],
   "source": [
    "tweet_date = \"Thu Apr 06 15:24:15 +0000 2017\"\n",
    "print(f\"The original date was formatted as: {tweet_date}\")\n",
    "\n",
    "tweet_stamp = datetime.strptime(tweet_date, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "print(\"We can format it differenly, such as:\", \n",
    "      datetime.strftime(tweet_stamp, '%Y--%d--%b--%a %H and %M and %S %z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017--4--6\n"
     ]
    }
   ],
   "source": [
    "print(tweet_stamp.year,tweet_stamp.month,tweet_stamp.day,sep=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timezones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timezone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot subtract time zone aware from non aware data\n",
      "1859 days, 15:35:26.902178\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(datetime.now() - tweet_stamp)\n",
    "except:\n",
    "    print(\"Cannot subtract time zone aware from non aware data\")\n",
    "    print(datetime.now(timezone.utc) - tweet_stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localisation and time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale \n",
    "from calendar import day_abbr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim']\n",
      "['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n"
     ]
    }
   ],
   "source": [
    "locale.setlocale(locale.LC_ALL, 'fr_FR.UTF-8') # French\n",
    "print([day_abbr[i] for i in range(7)])\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, '') # Local (English)\n",
    "print([day_abbr[i] for i in range(7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisiting the Movie Stack Exchange data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61184\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path().cwd().parent / \"data\"\n",
    "pickle_file = data_dir / \"movies_stack_df.pkl\"\n",
    "\n",
    "if pickle_file.exists():\n",
    "    stack_df = pickle.load(open(pickle_file ,'rb'))\n",
    "    print(len(stack_df))\n",
    "else:\n",
    "    print(\"Please download and clean the Stack_df data as done in \",\n",
    "          \"Chapter 10. See https://archive.org/download/stackexchange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-11-30 19:15:54.070000 <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "print(stack_df[\"CreationDate\"][0], type(stack_df[\"CreationDate\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(stack_df[\"CreationDate\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Datetime feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "74465     2017\n",
       "105929    2019\n",
       "89621     2018\n",
       "55084     2016\n",
       "23203     2014\n",
       "Name: CreationDate, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = stack_df[\"CreationDate\"].dt.year\n",
    "display(result.sample(5,random_state=12345))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_df[\"CreationDate\"].dt.year.hist();\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_vals = stack_df[\"CreationDate\"].dt.month.value_counts().sort_index()\n",
    "month_vals.index = [calendar.month_abbr[x] for x in month_vals.index]\n",
    "\n",
    "month_vals.plot(kind=\"bar\");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_vals = stack_df[\"CreationDate\"].dt.hour.value_counts().sort_index()\n",
    "hour_vals.index = [ f\"{x}h\" for x in hour_vals.index]\n",
    "hour_vals.plot(kind=\"bar\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "74465     08 Jun\n",
       "105929    27 Dec\n",
       "89621     11 Jun\n",
       "55084     06 Jun\n",
       "23203     19 Jul\n",
       "Name: CreationDate, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_df[\"CreationDate\"].dt.strftime(\"%d %b\").sample(5,random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling as a way to group by time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_df.resample('M', on=\"CreationDate\").sum().head(5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stack_df[[\"CreationDate\",\"Score\"]]\n",
    "        .resample('Y',on=\"CreationDate\")\n",
    "        .max().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1)\n",
    "\n",
    "sns.histplot(stack_df[\"CreationDate\"],\n",
    "             ax=ax1).set_xlabel(None)#.set_ylabel(None)\n",
    "ax1.set_ylabel(None) \n",
    "\n",
    "stack_df[[\"CreationDate\"]].resample('Y', \n",
    "    on=\"CreationDate\").count().plot(ax=ax2,legend=False).set_xlabel(None)\n",
    "ax2.set_ylabel(\"Count\") \n",
    "\n",
    "stack_df[[\"CreationDate\"]].resample('M',\n",
    "    on=\"CreationDate\").count().plot(ax=ax3,legend=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing and the Datetimeindex in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_mask = (stack_df[\"CreationDate\"]>= '2015-03-14') & \\\n",
    "            (stack_df[\"CreationDate\"]<  '2015-03-15')\n",
    "\n",
    "stack_df.iloc[:,:5][time_mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16719\n"
     ]
    }
   ],
   "source": [
    "# Counting posts within a two-year range\n",
    "mask2 = (stack_df[\"CreationDate\"] >= '2015') & \\\n",
    "        (stack_df[\"CreationDate\"] <  '2017')\n",
    "\n",
    "print(len(stack_df[mask2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = stack_df.copy()\n",
    "time_df['Id'] = stack_df.index\n",
    "time_df.set_index('CreationDate',inplace=True)\n",
    "time_df[[\"Id\",\"CleanBody\",\"Score\"]].sample(5, random_state=1984)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607\n",
      "600\n",
      "6496\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(time_df.loc[\"2015-06\"]),\n",
    "      len(time_df.loc[\"2015-07\"]),\n",
    "      len(time_df.loc[\"2018\"]),\n",
    "      len(time_df.sort_index().loc[\"2018-03-14\":\"2018-03-15\"]),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Moving window in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df[\"Score7d\"] = time_df[\"Score\"].rolling(7, center=True).mean()\n",
    "time_df[[\"Score\",\"Score7d\"]].head(8).style.format({\"Score7d\":\"{:.2f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df_mnth = time_df[[\"Score\",\"CommentCount\"]].resample('M').mean()\n",
    "display(time_df_mnth.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data in a rolling window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = time_df[[\"Score\"]].resample('D').mean()\n",
    "\n",
    "daily_df[\"Score7d\"] = daily_df[\"Score\"].rolling(7, center=True).mean()\n",
    "daily_df[\"Score30d\"] = daily_df[\"Score\"].rolling(30, center=True).mean()\n",
    "daily_df[\"Score60d\"] = daily_df[\"Score\"].rolling(60, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1)\n",
    "\n",
    "daily_df[\"Score7d\"].plot(ax=ax1, legend=True, sharex=ax3)\n",
    "daily_df[\"Score30d\"].plot(ax=ax2, legend=True, sharex=ax3)\n",
    "daily_df[\"Score60d\"].plot(ax=ax3, legend=True)\n",
    "\n",
    "ax3.set_xlabel(\"Average score of posts over time\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(daily_df[\"Score\"]\n",
    " .rolling(60, center=True, min_periods=55)\n",
    " .mean()\n",
    " .plot(legend=True,ylabel=\"Average post score\", xlabel=\"year\"));\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further explorations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions and reflections "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
