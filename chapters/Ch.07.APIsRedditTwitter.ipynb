{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing APIs: Abstracting from the web \n",
    "Thank you for checking out the code for: \n",
    "\n",
    "> Hogan, Bernie (2022, forthcoming) _From Social Science to Data Science_. Sage Publications. \n",
    "\n",
    "This notebook contains the code from the book, along with the headers and additional author notes that are not in the book as a way to help navigate the code. You can run this notebook in a browser by clicking the buttons below. \n",
    "    \n",
    "The version that is uploaded to GitHub should have all the results pasted, but the best way to follow along is to clear all outputs and then start afresh. To do this in Jupyter go the menu and select \"Kernel -> Restart Kernel and Clear all Outputs...\". To do this on Google Colab go to the menu and select \"Edit -> Clear all outputs\".\n",
    "    \n",
    "The most up-to-date version of this code can be found at https://www.github.com/berniehogan/fsstds \n",
    "\n",
    "Additional resources and teaching materials can be found on Sage's forthcoming website for this book. \n",
    "\n",
    "All code for the book and derivative code on the book's repository is released open source under the  MIT license. \n",
    "    \n",
    "\n",
    "[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/berniehogan/fsstds/main?filepath=chapters%2FCh.07.APIsRedditTwitter.ipynb)[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/berniehogan/fsstds/blob/main/chapters/Ch.07.APIsRedditTwitter.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Identifying yourself: Keys and Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.xxx.xxx.xxx\n"
     ]
    }
   ],
   "source": [
    "my_external_ip = requests.get(\"https://api.ipify.org\").text\n",
    "print(my_external_ip.split(\".\")[0] + \".xxx.xxx.xxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:\n",
      "Norwegian Forest Cat\n",
      "Description:\n",
      "The Norwegian Forest Cat is a sweet, loving cat. She appreciates praise and loves to interact with her parent. She makes a loving companion and bonds with her parents once she accepts them for her own. She is still a hunter at heart. She loves to chase toys as if they are real. She is territorial and patrols several times each day to make certain that all is fine.\n"
     ]
    }
   ],
   "source": [
    "s = requests.Session()\n",
    "s.headers.update({'x-api-key': 'aa1111bb-2222-22cc-dd3e-e44ffff5a66b'})\n",
    "\n",
    "req = s.get(\"https://api.thecatapi.com/v1/breeds/search?q=Norwegian\")\n",
    "results = json.loads(req.content)\n",
    "\n",
    "if len(results) > 0:\n",
    "    print(\"Name:\",results[0]['name'],\n",
    "          \"Description:\",results[0]['description'], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Securely using credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ['CONDA_PYTHON_EXE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-dotenv\n",
    "import dotenv\n",
    "\n",
    "ENV_PATH = f\"..{os.sep}.env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.set_key(ENV_PATH, \n",
    "    \"CAT_API_KEY\",\"aa1111bb-2222-22cc-dd3e-e44ffff5a66b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv(ENV_PATH)\n",
    "print(os.environ.get('CAT_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweet, Active, Intelligent, Social, Playful, Lively, Curious\n"
     ]
    }
   ],
   "source": [
    "s = requests.Session()\n",
    "s.headers.update({\"x-api-key\":os.environ['CAT_API_KEY']})\n",
    "\n",
    "req = s.get(\"https://api.thecatapi.com/v1/breeds/search?q=Norwegian\")\n",
    "print(json.loads(req.content)[0]['temperament'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Accessing Twitter Data through the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "# dotenv.set_key(ENV_PATH, \"TWITTER_BEARER_TOKEN\",\n",
    "# \"AAAAAAAAAAAAAAAAAAAAAI4bbbCCCCCCCCdEf%1GGggGgGgGgGGG222jk4l55%5LmMMmm66Nnn\n",
    "# 6OOooooPpPPp7qqqQ8rrrrr999r0SSSSSSS00tTt\")\n",
    "\n",
    "dotenv.load_dotenv(ENV_PATH) # This will refresh the environment variables\n",
    "print(len(os.environ.get('TWITTER_BEARER_TOKEN')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'meta'])\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "BEARER = os.environ[\"TWITTER_BEARER_TOKEN\"]\n",
    "headers = {\"Authorization\": f\"Bearer {BEARER}\"}\n",
    "\n",
    "QUERY = \"(muppet show) -is:retweet\"\n",
    "MAX_RESULTS = 10 \n",
    "\n",
    "params={\"query\": QUERY,\n",
    "        \"max_results\":MAX_RESULTS}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "assert response.status_code == 200, \\\n",
    "    f\"Code {response.status_code}. See error: {response.json()}\"\n",
    "\n",
    "tweets = response.json()\n",
    "print(tweets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Troubleshooting requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['data'][0] # Actual content simulated for book "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access rights and twitter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies for navigating Twitter's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'meta'])\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'query': QUERY,\n",
    "    'max_results':10,\n",
    "    'tweet.fields':\"id,author_id,conversation_id,created_at,\"+\n",
    "                   \"in_reply_to_user_id\"}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "assert response.status_code == 200, \\\n",
    "    f\"Code {response.status_code}. See error: {response.json()}\"\n",
    "\n",
    "tweets = response.json()\n",
    "print(tweets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(tweets['data'])\n",
    "df[[\"id\",\"conversation_id\",\"author_id\",\"in_reply_to_user_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'includes', 'meta'])\n"
     ]
    }
   ],
   "source": [
    "params['expansions'] = \"author_id,geo.place_id\"\n",
    "params['user.fields'] = \"id,username,name,description,public_metrics\"\n",
    "params['place.fields'] = \"id,country,country_code,full_name\"\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "assert response.status_code == 200, \\\n",
    "    f\"Code {response.status_code}. See error: {response.json()}\"\n",
    "\n",
    "tweets = response.json()\n",
    "print(tweets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.json_normalize(tweets['includes']['users'])\n",
    "users_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tweet counts to manage requests  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={'query': QUERY}\n",
    "url = \"https://api.twitter.com/2/tweets/counts/recent\"\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "assert response.status_code == 200, \\\n",
    "    print(\"There was an error retrieving the results:\", response)\n",
    "\n",
    "count_data = response.json()\n",
    "\n",
    "len(count_data[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_tweet_count': 1113}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data[\"meta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using an API wrapper to simplify data access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5.0\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "print(praw.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting reddit data using `praw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dotenv.set_key(ENV_PATH, 'REDDIT_CLIENT_ID','AAA11bbbCCdEE2fGGh3ijK')\n",
    "# dotenv.set_key(ENV_PATH, 'REDDIT_CLIENT_SECRET',\n",
    "#               'aBcDe1FgGgHIJ2KlMnO3PQRs-TuvwX')\n",
    "# dotenv.set_key(ENV_PATH, 'REDDIT_USER', 'berniehogan')\n",
    "\n",
    "dotenv.load_dotenv(ENV_PATH);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = f\"MacOS:redditapitester:v1 (by u/{os.environ['REDDIT_USER']})\"\n",
    "\n",
    "redd = praw.Reddit(user_agent = user_agent,\n",
    "                   client_id = os.environ['REDDIT_CLIENT_ID'],\n",
    "                   client_secret = os.environ['REDDIT_CLIENT_SECRET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_post = next(redd.front.hot())\n",
    "\n",
    "print(\"The hot post now is:\", example_post.title)\n",
    "print(\"Submitted by: u/\", example_post.author.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building a comment tree on Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 7o6bxv\n",
      "Before: 159\n"
     ]
    }
   ],
   "source": [
    "example_post = redd.submission(\"7o6bxv\") # This will refresh the object.\n",
    "\n",
    "print(\"Title:\", example_post)\n",
    "print(\"Before:\",len(example_post.comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: 468\n"
     ]
    }
   ],
   "source": [
    "example_post.comments.replace_more(limit=None)\n",
    "print(\"After:\",len(example_post.comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frank was mentioned in 182 comments or 17.2% of the time\n"
     ]
    }
   ],
   "source": [
    "comment_list = example_post.comments.list()\n",
    "\n",
    "mentions = len([comment for comment in comment_list \n",
    "                if \"Frank\" in comment.body])\n",
    "\n",
    "print(f\"Frank was mentioned in {mentions} comments\",\n",
    "      f\"or {mentions/len(comment_list):0.1%} of the time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerations for a data collection pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version control systems and servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing data remotely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter in the Browser as an alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs and Epistemology: How data access can mean knowledge access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further reading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions and reflections "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
